{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import nltk\n",
    "import pickle\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"train.iob\",\"r\",encoding=\"utf-8\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=[]\n",
    "history=[[\"<null>\"]]\n",
    "for d in data:\n",
    "    if d==\"\\n\":\n",
    "        history=[[\"<null>\"]]\n",
    "        continue\n",
    "    dd = d.replace(\"\\n\",\"\").split(\"|||\")\n",
    "    if len(dd)==1:\n",
    "        bot = tagger.morphs(dd[0])\n",
    "        history.append(bot)\n",
    "    else:\n",
    "        user = dd[0].split()\n",
    "        tag = dd[1].split()\n",
    "        intent = dd[2]\n",
    "        temp = deepcopy(history)\n",
    "        train_data.append([temp,user,tag,intent])\n",
    "        history.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['<null>'],\n",
       "  ['will', 'it', 'rain', 'this', 'week'],\n",
       "  ['What',\n",
       "   'city',\n",
       "   'are',\n",
       "   'you',\n",
       "   'wanting',\n",
       "   'to',\n",
       "   'know',\n",
       "   'if',\n",
       "   'it',\n",
       "   \"'\",\n",
       "   's',\n",
       "   'going',\n",
       "   'to',\n",
       "   'rain',\n",
       "   '?']],\n",
       " ['Menlo', 'Park'],\n",
       " ['B-location', 'I-location'],\n",
       " 'weather']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "historys, currents, slots, intents = list(zip(*train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(flatten(currents)))\n",
    "slot_vocab = list(set(flatten(slots)))\n",
    "intent_vocab = list(set(intents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index={\"<pad>\" : 0, \"<unk>\" : 1, \"<null>\" : 2, \"<s>\" : 3, \"</s>\" : 4}\n",
    "for vo in vocab:\n",
    "    if word2index.get(vo)==None:\n",
    "        word2index[vo] = len(word2index)\n",
    "        \n",
    "slot2index={\"<pad>\" : 0}\n",
    "for vo in slot_vocab:\n",
    "    if slot2index.get(vo)==None:\n",
    "        slot2index[vo] = len(slot2index)\n",
    "        \n",
    "intent2index={}\n",
    "for vo in intent_vocab:\n",
    "    if intent2index.get(vo)==None:\n",
    "        intent2index[vo] = len(intent2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in train_data:\n",
    "    for i,history in enumerate(t[0]):\n",
    "        t[0][i] = prepare_sequence(history, word2index).view(1, -1)\n",
    "\n",
    "    t[1] = prepare_sequence(t[1], word2index).view(1, -1)\n",
    "    t[2] = prepare_sequence(t[2], slot2index).view(1, -1)\n",
    "    t[3] = torch.LongTensor([intent2index[t[3]]]).view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDEN(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_size,hidden_size,slot_size,intent_size):\n",
    "        super(SDEN,self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size,embed_size)\n",
    "        self.bigru_m = nn.GRU(embed_size,hidden_size,batch_first=True,bidirectional=True)\n",
    "        self.bigru_c = nn.GRU(embed_size,hidden_size,batch_first=True,bidirectional=True)\n",
    "        self.context_encoder = nn.Sequential(nn.Linear(hidden_size*4,hidden_size*2),\n",
    "                                                               nn.Sigmoid())\n",
    "        self.session_encoder = nn.GRU(hidden_size*2,hidden_size*2,batch_first=True,bidirectional=True)\n",
    "        \n",
    "        self.decoder_1 = nn.GRU(embed_size,hidden_size*2,batch_first=True,bidirectional=True)\n",
    "        self.decoder_2 = nn.LSTM(hidden_size*4,hidden_size*2,batch_first=True,bidirectional=True)\n",
    "        \n",
    "        self.intent_linear = nn.Linear(hidden_size*4,intent_size)\n",
    "        self.slot_linear = nn.Linear(hidden_size*4,slot_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self,history,current):\n",
    "        batch_size = len(history)\n",
    "        H= [] # encoded history\n",
    "        for h in history:\n",
    "            mask = h.eq(0)\n",
    "            embeds = self.embed(h)\n",
    "            embeds = self.dropout(embeds)\n",
    "            outputs, hidden = self.bigru_m(embeds)\n",
    "            real_hidden = []\n",
    "\n",
    "            for i, o in enumerate(outputs): # B,T,D\n",
    "                real_length = mask[i].data.tolist().count(0) \n",
    "                real_hidden.append(o[real_length - 1])\n",
    "\n",
    "            H.append(torch.cat(real_hidden).view(h.size(0), -1).unsqueeze(0))\n",
    "        \n",
    "        M = torch.cat(H) # B,T_C,2H\n",
    "        M = self.dropout(M)\n",
    "        embeds = self.embed(current)\n",
    "        embeds = self.dropout(embeds)\n",
    "        mask = current.eq(0)\n",
    "        outputs, hidden = self.bigru_c(embeds)\n",
    "        real_hidden=[]\n",
    "        for i, o in enumerate(outputs): # B,T,D\n",
    "            real_length = mask[i].data.tolist().count(0) \n",
    "            real_hidden.append(o[real_length - 1])\n",
    "        C = torch.cat(real_hidden).view(current.size(0),1, -1) # B,1,2H\n",
    "        C = self.dropout(C)\n",
    "        \n",
    "        CONCAT = []\n",
    "        for i in range(batch_size):\n",
    "            m = M[i] # T_c,2H\n",
    "            c = C[i] # 1,2H\n",
    "            c = c.expand_as(m)\n",
    "            cat = torch.cat([m,c],1)\n",
    "            CONCAT.append(cat.unsqueeze(0))\n",
    "        CONCAT = torch.cat(CONCAT)\n",
    "        \n",
    "        G = self.context_encoder(CONCAT)\n",
    "        \n",
    "        _,H = self.session_encoder(G) # 2,B,2H\n",
    "        weight = next(self.parameters())\n",
    "        cell_state = weight.new_zeros(H.size())\n",
    "        O_1,_ = self.decoder_1(embeds)\n",
    "        O_1 = self.dropout(O_1)\n",
    "        \n",
    "        O_2,(S_2,_) = self.decoder_2(O_1,(H,cell_state))\n",
    "        O_2 = self.dropout(O_2)\n",
    "        S = torch.cat([s for s in S_2],1)\n",
    "        \n",
    "        intent_prob = self.intent_linear(S)\n",
    "        slot_prob = self.slot_linear(O_2.contiguous().view(O_2.size(0)*O_2.size(1),-1))\n",
    "        \n",
    "        return slot_prob, intent_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 20\n",
    "BATCH = 32\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SDEN(len(word2index),100,64,len(slot2index),len(intent2index))\n",
    "slot_loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "intent_loss_function = nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=LR)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(gamma=0.1,milestones=[EPOCH//4,EPOCH//2],optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10] [0/961] mean_loss : 4.612\n",
      "[0/10] [20/961] mean_loss : 3.109\n",
      "[0/10] [40/961] mean_loss : 2.019\n",
      "[0/10] [60/961] mean_loss : 1.889\n",
      "[0/10] [80/961] mean_loss : 1.654\n",
      "[0/10] [100/961] mean_loss : 1.527\n",
      "[0/10] [120/961] mean_loss : 1.458\n",
      "[0/10] [140/961] mean_loss : 1.335\n",
      "[0/10] [160/961] mean_loss : 1.174\n",
      "[0/10] [180/961] mean_loss : 1.053\n",
      "[0/10] [200/961] mean_loss : 1.052\n",
      "[0/10] [220/961] mean_loss : 1.008\n",
      "[0/10] [240/961] mean_loss : 1.024\n",
      "[0/10] [260/961] mean_loss : 0.959\n",
      "[0/10] [280/961] mean_loss : 0.937\n",
      "[0/10] [300/961] mean_loss : 0.932\n",
      "[0/10] [320/961] mean_loss : 0.826\n",
      "[0/10] [340/961] mean_loss : 0.827\n",
      "[0/10] [360/961] mean_loss : 0.874\n",
      "[0/10] [380/961] mean_loss : 0.836\n",
      "[0/10] [400/961] mean_loss : 0.867\n",
      "[0/10] [420/961] mean_loss : 0.773\n",
      "[0/10] [440/961] mean_loss : 0.742\n",
      "[0/10] [460/961] mean_loss : 0.779\n",
      "[0/10] [480/961] mean_loss : 0.705\n",
      "[0/10] [500/961] mean_loss : 0.692\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-73ba55b2ac9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_s\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(EPOCH):\n",
    "    losses=[]\n",
    "    scheduler.step()\n",
    "    for i,batch in enumerate(data_loader(train_data,BATCH,True)):\n",
    "        h,c,slot,intent = pad_to_batch(batch,word2index,slot2index)\n",
    "        h = [hh.to(device) for hh in h]\n",
    "        c = c.to(device)\n",
    "        slot = slot.to(device)\n",
    "        intent = intent.to(device)\n",
    "        model.zero_grad()\n",
    "        slot_p, intent_p = model(h,c)\n",
    "\n",
    "        loss_s = slot_loss_function(slot_p,slot.view(-1))\n",
    "        loss_i = intent_loss_function(intent_p,intent.view(-1))\n",
    "        loss = loss_s + loss_i\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            print(\"[%d/%d] [%d/%d] mean_loss : %.3f\" % (epoch,EPOCH,i,len(train_data)//BATCH,np.mean(losses)))\n",
    "            losses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('../dataset/kvret/kvret_dev_public.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[ 2]]),\n",
       "  tensor([[ 1131,   640,  1126,   640,   555,   284,   953,   698,   400,\n",
       "             990,   640,   555,  1149,   283,    68,   530,  1077]]),\n",
       "  tensor([[    1,   990,   670,   159,  1109,   673,   944,   236,   698,\n",
       "             382,   593,   595,   436,   542,   514]]),\n",
       "  tensor([[ 1042,   555,  1126,   698,  1109,   990,  1077]]),\n",
       "  tensor([[ 1118,   539,     1,   509,   782,   326,    70,   514]])],\n",
       " tensor([[ 983,  640,  222,  251,  471]]),\n",
       " tensor([[ 16,  16,  16,  16,  16]]),\n",
       " tensor([[ 2]])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2slot = {v:k for k,v in slot2index.items()}\n",
    "index2intent = {v:k for k,v in intent2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = random.choice(range(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schedule my 10 am dentist appointment on Friday with my father.\n",
      "['O', 'O', 'B-event', 'O', 'I-event', 'I-event', 'O', 'B-date', 'O', 'O', 'O', 'O']\n",
      "schedule\n",
      "\n",
      "\n",
      "List my current schedule. \n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "navigate\n",
      "\n",
      "\n",
      "List my schedule for Friday.\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "schedule\n",
      "\n",
      "\n",
      "Thank you so much!\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "thanks\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = random.choice(range(len(data)))\n",
    "history=[prepare_sequence([\"<null>\"],word2index).view(1,-1)]\n",
    "for d in data[index]['dialogue']:\n",
    "    \n",
    "    if d['turn']=='assistant':\n",
    "        phrase = nltk.word_tokenize(d['data']['utterance'])\n",
    "        phrase = prepare_sequence(phrase,word2index).view(1,-1)\n",
    "        history.append(phrase)\n",
    "    else:\n",
    "        h = pad_to_history(history,word2index)\n",
    "        c = nltk.word_tokenize(d['data']['utterance'])\n",
    "        c = prepare_sequence(c,word2index).view(1,-1)\n",
    "        with torch.no_grad():\n",
    "            slot_p, intent_p = model(h,c)\n",
    "        \n",
    "        slots = slot_p.max(1)[1]\n",
    "        intent = intent_p.max(1)[1]\n",
    "        slots = [index2slot[i] for i in slots.tolist()]\n",
    "        intent = index2intent[intent.item()]\n",
    "        print(d['data']['utterance'])\n",
    "        print(slots)\n",
    "        print(intent)\n",
    "        print(\"\\n\")\n",
    "        history.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = model.cpu()\n",
    "torch.save(model.state_dict(),'sden.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(word2index,open('vocab.pkl','wb'))\n",
    "pickle.dump(slot2index,open('slot.pkl','wb'))\n",
    "pickle.dump(intent2index,open('intent.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
