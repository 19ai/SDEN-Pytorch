{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "import nltk\n",
    "import re\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nlp.stanford.edu/blog/a-new-multi-turn-multi-domain-task-oriented-dialogue-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 'TO')]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(['to'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_iob(phrase,goal_tracker):\n",
    "    resolution = re.compile('-\\d')\n",
    "    phrase = deepcopy(phrase.lower())\n",
    "    goal_tracker = deepcopy(goal_tracker)\n",
    "    order = [[(k,v),phrase.index(v)] for k,v in goal_tracker.items() if v !=None and v in phrase]\n",
    "    order = sorted(order, key=lambda x: x[1])\n",
    "    goal_tracker = OrderedDict([o[0] for o in order])\n",
    "    pos = nltk.word_tokenize(phrase)\n",
    "    tag=[\"O\"]*len(pos)\n",
    "    for k,v in goal_tracker.items():\n",
    "        B=True\n",
    "        if (v in phrase):\n",
    "            for i,p in enumerate(pos):\n",
    "                if p!=\"<MASK>\" and (p in v):\n",
    "                    if len(p)<=2 and i < len(pos)-1:\n",
    "                        if len(p)==2 and 'N' not in nltk.pos_tag([p])[0][1]:\n",
    "                            continue\n",
    "                        elif pos[i+1] not in v:\n",
    "                            continue\n",
    "                    if B:\n",
    "                        tag[i] = 'B-'+k\n",
    "                        B=False\n",
    "                        pos[i]=\"<MASK>\"\n",
    "                    else:\n",
    "                        if i!=0 and tag[i-1][0] in ['B','I']: \n",
    "                            tag[i] = 'I-'+k\n",
    "                            pos[i]=\"<MASK>\"\n",
    "    tag = [resolution.sub('',t) for t in tag]\n",
    "    return tag\n",
    "\n",
    "\n",
    "def get_phrase(phrase,value):\n",
    "    token = nltk.word_tokenize(phrase.lower())\n",
    "    value = value.lower()\n",
    "    token = [w[0] for w in nltk.pos_tag(token) if w[1].isalpha()]\n",
    "    unigram = [[t] for t in token]\n",
    "    bigram = list(nltk.ngrams(token,2))\n",
    "    trigram = list(nltk.ngrams(token,3))\n",
    "    fourgram = list(nltk.ngrams(token,4))\n",
    "    candit = unigram+bigram+trigram+fourgram\n",
    "    value = nltk.word_tokenize(value)\n",
    "    \n",
    "    result = []\n",
    "    for c in candit:\n",
    "        r = SequenceMatcher(None,c,value)\n",
    "        result.append([r.ratio(),\" \".join(c)])\n",
    "    \n",
    "    result = sorted(result,key=lambda x:x[0],reverse=True)\n",
    "    return result[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'B-per']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_iob('he is Good',{'per-1':'he','per-2':'good'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('../dataset/kvret/kvret_train_public.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = json.load(open('../dataset/kvret/kvret_entities.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['poi_type', 'poi', 'agenda', 'event', 'traffic_info', 'temperature', 'location', 'date', 'weekly_time', 'distance', 'party', 'room', 'weather_attribute', 'time'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dialogue', 'scenario'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver  :  where's the nearest parking garage\n",
      "assistant  :  The nearest parking garage is Dish Parking at 550 Alester Ave. Would you like directions there? \n",
      "driver  :  Yes, please set directions via a route that avoids all heavy traffic if possible. \n",
      "assistant  :  It looks like there is a road block being reported on the route but I will still find the quickest route to 550 Alester Ave. \n",
      "driver  :  Thanks so much for your help. \n",
      "assistant  :  You're very welcome!\n"
     ]
    }
   ],
   "source": [
    "for d in data[0]['dialogue']:\n",
    "    print(d['turn'],' : ',d['data']['utterance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('../dataset/kvret/kvret_train_public.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "diags=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2425/2425 [00:09<00:00, 252.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for dindex in tqdm(range(len(data))):\n",
    "    diag=[]\n",
    "    length = len(data[dindex]['dialogue'])\n",
    "    if length==0: continue\n",
    "    for i in range(length-1):\n",
    "        if data[dindex]['dialogue'][i]['turn']=='driver':\n",
    "            task = data[dindex]['scenario']['task']['intent']\n",
    "            phrase = data[dindex]['dialogue'][i]['data']['utterance']\n",
    "            if phrase=='': continue\n",
    "            if data[dindex]['dialogue'][i+1]['data'].get('slots'):\n",
    "                slot = data[dindex]['dialogue'][i+1]['data']['slots']\n",
    "                for k,v in slot.items():\n",
    "                    vv = get_phrase(phrase,v)\n",
    "                    slot[k]=vv\n",
    "                if slot.get('poi'): \n",
    "                    task = task+'_request_poi'\n",
    "                    slot.pop('poi')\n",
    "                if slot.get('address'):\n",
    "                    task = task+'_request_address'\n",
    "                    slot.pop('address')\n",
    "            else:\n",
    "                slot = {'dummy' : '<DUMMMMMMYYYYYY!!>'}\n",
    "            if data[dindex]['dialogue'][i+1]['data']['end_dialogue']:\n",
    "                task = 'thanks'\n",
    "            bio = make_iob(phrase,slot)\n",
    "            diag.append([nltk.word_tokenize(phrase),bio,task])\n",
    "        else:\n",
    "            phrase = data[dindex]['dialogue'][i]['data']['utterance']\n",
    "            diag.append([nltk.word_tokenize(phrase),'BOT','BOT'])\n",
    "    \n",
    "    last = data[dindex]['dialogue'][-1]['data']['utterance']\n",
    "    diag.append([nltk.word_tokenize(last),'BOT','BOT'])\n",
    "    diags.append(diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'data': {'end_dialogue': False, 'utterance': 'check forecast for new york'},\n",
       "  'turn': 'driver'},\n",
       " {'data': {'end_dialogue': False,\n",
       "   'requested': {'date': False, 'location': True, 'weather_attribute': True},\n",
       "   'slots': {'location': 'new york'},\n",
       "   'utterance': 'The weather this week will be hail and rain on Thursday and Sunday, with the lowest temperature being 20F and the highest 90F, Monday will be the only hot day. '},\n",
       "  'turn': 'assistant'},\n",
       " {'data': {'end_dialogue': False,\n",
       "   'utterance': 'Will it be overcast on friday?'},\n",
       "  'turn': 'driver'},\n",
       " {'data': {'end_dialogue': False,\n",
       "   'requested': {'date': True, 'location': False, 'weather_attribute': True},\n",
       "   'slots': {'date': 'friday', 'weather_attribute': 'overcast'},\n",
       "   'utterance': 'On Friday it will be cloudy on New York'},\n",
       "  'turn': 'assistant'},\n",
       " {'data': {'end_dialogue': False, 'utterance': 'Thank you!'},\n",
       "  'turn': 'driver'},\n",
       " {'data': {'end_dialogue': True,\n",
       "   'requested': {'date': False, 'location': False, 'weather_attribute': False},\n",
       "   'slots': {},\n",
       "   'utterance': \"You're welcome!\"},\n",
       "  'turn': 'assistant'}]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[6]['dialogue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.iob','w',encoding='utf-8') as f:\n",
    "    for diag in diags:\n",
    "        for utter in diag:\n",
    "            if utter[1]=='BOT':\n",
    "                f.write(' '.join(utter[0])+'\\n')\n",
    "            else:\n",
    "                f.write(' '.join(utter[0])+\"|||\"+' '.join(utter[1])+\"|||\"+utter[2]+\"\\n\")\n",
    "        \n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Task 단위 분류 및 레이블링\n",
    "* 오류 수정\n",
    "* 모델링 (우선 도메인부터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
