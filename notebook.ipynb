{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import nltk\n",
    "import pickle\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"data/train.iob\",\"r\",encoding=\"utf-8\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=[]\n",
    "history=[[\"<null>\"]]\n",
    "for d in data:\n",
    "    if d==\"\\n\":\n",
    "        history=[[\"<null>\"]]\n",
    "        continue\n",
    "    dd = d.replace(\"\\n\",\"\").split(\"|||\")\n",
    "    if len(dd)==1:\n",
    "        bot = tagger.morphs(dd[0])\n",
    "        history.append(bot)\n",
    "    else:\n",
    "        user = dd[0].split()\n",
    "        tag = dd[1].split()\n",
    "        intent = dd[2]\n",
    "        temp = deepcopy(history)\n",
    "        train_data.append([temp,user,tag,intent])\n",
    "        history.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "historys, currents, slots, intents = list(zip(*train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(flatten(currents)))\n",
    "slot_vocab = list(set(flatten(slots)))\n",
    "intent_vocab = list(set(intents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index={\"<pad>\" : 0, \"<unk>\" : 1, \"<null>\" : 2, \"<s>\" : 3, \"</s>\" : 4}\n",
    "for vo in vocab:\n",
    "    if word2index.get(vo)==None:\n",
    "        word2index[vo] = len(word2index)\n",
    "        \n",
    "slot2index={\"<pad>\" : 0}\n",
    "for vo in slot_vocab:\n",
    "    if slot2index.get(vo)==None:\n",
    "        slot2index[vo] = len(slot2index)\n",
    "        \n",
    "intent2index={}\n",
    "for vo in intent_vocab:\n",
    "    if intent2index.get(vo)==None:\n",
    "        intent2index[vo] = len(intent2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in train_data:\n",
    "    for i,history in enumerate(t[0]):\n",
    "        t[0][i] = prepare_sequence(history, word2index).view(1, -1)\n",
    "\n",
    "    t[1] = prepare_sequence(t[1], word2index).view(1, -1)\n",
    "    t[2] = prepare_sequence(t[2], slot2index).view(1, -1)\n",
    "    t[3] = torch.LongTensor([intent2index[t[3]]]).view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDEN(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_size,hidden_size,slot_size,intent_size,pad_idx=0):\n",
    "        super(SDEN,self).__init__()\n",
    "        \n",
    "        self.pad_idx = 0\n",
    "        self.embed = nn.Embedding(vocab_size,embed_size,padding_idx=self.pad_idx)\n",
    "        self.bigru_m = nn.GRU(embed_size,hidden_size,batch_first=True,bidirectional=True)\n",
    "        self.bigru_c = nn.GRU(embed_size,hidden_size,batch_first=True,bidirectional=True)\n",
    "        self.context_encoder = nn.Sequential(nn.Linear(hidden_size*4,hidden_size*2),\n",
    "                                                               nn.Sigmoid())\n",
    "        self.session_encoder = nn.GRU(hidden_size*2,hidden_size*2,batch_first=True,bidirectional=True)\n",
    "        \n",
    "        self.decoder_1 = nn.GRU(embed_size,hidden_size*2,batch_first=True,bidirectional=True)\n",
    "        self.decoder_2 = nn.LSTM(hidden_size*4,hidden_size*2,batch_first=True,bidirectional=True)\n",
    "        \n",
    "        self.intent_linear = nn.Linear(hidden_size*4,intent_size)\n",
    "        self.slot_linear = nn.Linear(hidden_size*4,slot_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self,history,current):\n",
    "        batch_size = len(history)\n",
    "        H= [] # encoded history\n",
    "        for h in history:\n",
    "            mask = h.eq(self.pad_idx)\n",
    "            embeds = self.embed(h)\n",
    "            embeds = self.dropout(embeds)\n",
    "            outputs, hidden = self.bigru_m(embeds)\n",
    "            real_hidden = []\n",
    "\n",
    "            for i, o in enumerate(outputs): # B,T,D\n",
    "                real_length = mask[i].tolist().count(0) \n",
    "                real_hidden.append(o[real_length - 1])\n",
    "\n",
    "            H.append(torch.cat(real_hidden).view(h.size(0), -1).unsqueeze(0))\n",
    "        \n",
    "        M = torch.cat(H) # B,T_C,2H\n",
    "        M = self.dropout(M)\n",
    "        embeds = self.embed(current)\n",
    "        embeds = self.dropout(embeds)\n",
    "        mask = current.eq(self.pad_idx)\n",
    "        outputs, hidden = self.bigru_c(embeds)\n",
    "        real_hidden=[]\n",
    "        for i, o in enumerate(outputs): # B,T,D\n",
    "            real_length = mask[i].tolist().count(0) \n",
    "            real_hidden.append(o[real_length - 1])\n",
    "        C = torch.cat(real_hidden).view(current.size(0),1, -1) # B,1,2H\n",
    "        C = self.dropout(C)\n",
    "        \n",
    "        C = C.repeat(1,M.size(1),1) \n",
    "        CONCAT = torch.cat([M,C],-1) # B,T_c,4H\n",
    "        \n",
    "        G = self.context_encoder(CONCAT)\n",
    "        \n",
    "        _,H = self.session_encoder(G) # 2,B,2H\n",
    "        weight = next(self.parameters())\n",
    "        cell_state = weight.new_zeros(H.size())\n",
    "        O_1,_ = self.decoder_1(embeds)\n",
    "        O_1 = self.dropout(O_1)\n",
    "        \n",
    "        O_2,(S_2,_) = self.decoder_2(O_1,(H,cell_state))\n",
    "        O_2 = self.dropout(O_2)\n",
    "        S = torch.cat([s for s in S_2],1)\n",
    "        \n",
    "        intent_prob = self.intent_linear(S)\n",
    "        slot_prob = self.slot_linear(O_2.contiguous().view(O_2.size(0)*O_2.size(1),-1))\n",
    "        \n",
    "        return slot_prob, intent_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 20\n",
    "BATCH = 32\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SDEN(len(word2index),100,64,len(slot2index),len(intent2index),word2index['<pad>'])\n",
    "slot_loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "intent_loss_function = nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=LR)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(gamma=0.1,milestones=[EPOCH//4,EPOCH//2],optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/20] [0/961] mean_loss : 4.543\n",
      "[0/20] [100/961] mean_loss : 2.027\n",
      "[0/20] [200/961] mean_loss : 1.189\n",
      "[0/20] [300/961] mean_loss : 0.965\n",
      "[0/20] [400/961] mean_loss : 0.848\n",
      "[0/20] [500/961] mean_loss : 0.757\n",
      "[0/20] [600/961] mean_loss : 0.716\n",
      "[0/20] [700/961] mean_loss : 0.658\n",
      "[0/20] [800/961] mean_loss : 0.634\n",
      "[0/20] [900/961] mean_loss : 0.569\n",
      "[1/20] [0/961] mean_loss : 0.622\n",
      "[1/20] [100/961] mean_loss : 0.556\n",
      "[1/20] [200/961] mean_loss : 0.538\n",
      "[1/20] [300/961] mean_loss : 0.536\n",
      "[1/20] [400/961] mean_loss : 0.517\n",
      "[1/20] [500/961] mean_loss : 0.512\n",
      "[1/20] [600/961] mean_loss : 0.498\n",
      "[1/20] [700/961] mean_loss : 0.472\n",
      "[1/20] [800/961] mean_loss : 0.482\n",
      "[1/20] [900/961] mean_loss : 0.487\n",
      "[2/20] [0/961] mean_loss : 0.331\n",
      "[2/20] [100/961] mean_loss : 0.437\n",
      "[2/20] [200/961] mean_loss : 0.458\n",
      "[2/20] [300/961] mean_loss : 0.432\n",
      "[2/20] [400/961] mean_loss : 0.437\n",
      "[2/20] [500/961] mean_loss : 0.437\n",
      "[2/20] [600/961] mean_loss : 0.443\n",
      "[2/20] [700/961] mean_loss : 0.436\n",
      "[2/20] [800/961] mean_loss : 0.403\n",
      "[2/20] [900/961] mean_loss : 0.407\n",
      "[3/20] [0/961] mean_loss : 0.357\n",
      "[3/20] [100/961] mean_loss : 0.397\n",
      "[3/20] [200/961] mean_loss : 0.396\n",
      "[3/20] [300/961] mean_loss : 0.383\n",
      "[3/20] [400/961] mean_loss : 0.392\n",
      "[3/20] [500/961] mean_loss : 0.393\n",
      "[3/20] [600/961] mean_loss : 0.399\n",
      "[3/20] [700/961] mean_loss : 0.385\n",
      "[3/20] [800/961] mean_loss : 0.401\n",
      "[3/20] [900/961] mean_loss : 0.383\n",
      "[4/20] [0/961] mean_loss : 0.641\n",
      "[4/20] [100/961] mean_loss : 0.378\n",
      "[4/20] [200/961] mean_loss : 0.379\n",
      "[4/20] [300/961] mean_loss : 0.361\n",
      "[4/20] [400/961] mean_loss : 0.366\n",
      "[4/20] [500/961] mean_loss : 0.345\n",
      "[4/20] [600/961] mean_loss : 0.364\n",
      "[4/20] [700/961] mean_loss : 0.351\n",
      "[4/20] [800/961] mean_loss : 0.355\n",
      "[4/20] [900/961] mean_loss : 0.363\n",
      "[5/20] [0/961] mean_loss : 0.423\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d066d97f708c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mintent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mslot_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintent_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslot_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslot_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-d03647b2e307>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, history, current)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigru_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mreal_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mresetgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_r\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0minputgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mnewgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_n\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresetgate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewgate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minputgate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnewgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m     \"\"\"\n\u001b[0;32m--> 974\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(EPOCH):\n",
    "    losses=[]\n",
    "    scheduler.step()\n",
    "    for i,batch in enumerate(data_loader(train_data,BATCH,True)):\n",
    "        h,c,slot,intent = pad_to_batch(batch,word2index,slot2index)\n",
    "        h = [hh.to(device) for hh in h]\n",
    "        c = c.to(device)\n",
    "        slot = slot.to(device)\n",
    "        intent = intent.to(device)\n",
    "        model.zero_grad()\n",
    "        slot_p, intent_p = model(h,c)\n",
    "\n",
    "        loss_s = slot_loss_function(slot_p,slot.view(-1))\n",
    "        loss_i = intent_loss_function(intent_p,intent.view(-1))\n",
    "        loss = loss_s + loss_i\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"[%d/%d] [%d/%d] mean_loss : %.3f\" % (epoch,EPOCH,i,len(train_data)//BATCH,np.mean(losses)))\n",
    "            losses=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2slot = {v:k for k,v in slot2index.items()}\n",
    "index2intent = {v:k for k,v in intent2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"data/dev.iob\",\"r\",encoding=\"utf-8\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data=[]\n",
    "history=[[\"<null>\"]]\n",
    "for d in data:\n",
    "    if d==\"\\n\":\n",
    "        history=[[\"<null>\"]]\n",
    "        continue\n",
    "    dd = d.replace(\"\\n\",\"\").split(\"|||\")\n",
    "    if len(dd)==1:\n",
    "        bot = tagger.morphs(dd[0])\n",
    "        history.append(bot)\n",
    "    else:\n",
    "        user = dd[0].split()\n",
    "        tag = dd[1].split()\n",
    "        intent = dd[2]\n",
    "        temp = deepcopy(history)\n",
    "        dev_data.append([temp,user,tag,intent])\n",
    "        history.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in dev_data:\n",
    "    for i,history in enumerate(t[0]):\n",
    "        t[0][i] = prepare_sequence(history, word2index).view(1, -1)\n",
    "\n",
    "    t[1] = prepare_sequence(t[1], word2index).view(1, -1)\n",
    "    t[2] = prepare_sequence(t[2], slot2index).view(1, -1)\n",
    "    t[3] = torch.LongTensor([intent2index[t[3]]]).view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9588724584103512\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "preds=[]\n",
    "labels=[]\n",
    "hits=0\n",
    "with torch.no_grad():\n",
    "    for i,batch in enumerate(data_loader(dev_data,BATCH,True)):\n",
    "        h,c,slot,intent = pad_to_batch(batch,word2index,slot2index)\n",
    "        h = [hh.to(device) for hh in h]\n",
    "        c = c.to(device)\n",
    "        slot = slot.to(device)\n",
    "        intent = intent.to(device)\n",
    "        slot_p, intent_p = model(h,c)\n",
    "        \n",
    "        preds.extend([index2slot[i] for i in slot_p.max(1)[1].tolist()])\n",
    "        labels.extend([index2slot[i] for i in slot.view(-1).tolist()])\n",
    "        hits+=torch.eq(intent_p.max(1)[1],intent.view(-1)).sum().item()\n",
    "        \n",
    "        \n",
    "print(hits/len(dev_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_labels = sorted(\n",
    "    list(set(labels) - {'O','<pad>'}),\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [[y] for y in preds] # this is because sklearn_crfsuite.metrics function flatten inputs\n",
    "labels = [[y] for y in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           B-agenda      1.000     0.333     0.500         9\n",
      "           I-agenda      0.004     0.545     0.008        11\n",
      "             B-date      0.312     0.818     0.452       461\n",
      "             I-date      0.124     0.982     0.220       283\n",
      "         B-distance      0.583     0.744     0.653       242\n",
      "         I-distance      0.341     0.311     0.326        90\n",
      "            B-event      0.837     0.815     0.826       259\n",
      "            I-event      0.799     0.924     0.857       172\n",
      "         B-location      0.841     0.898     0.869       325\n",
      "         I-location      0.703     0.981     0.819       157\n",
      "            B-party      0.883     0.978     0.929        93\n",
      "            I-party      0.438     0.700     0.538        10\n",
      "         B-poi_type      0.645     0.789     0.710       265\n",
      "         I-poi_type      0.413     0.842     0.554       146\n",
      "             B-room      1.000     0.364     0.533        11\n",
      "             I-room      0.084     1.000     0.155        10\n",
      "             B-time      0.459     0.629     0.530        97\n",
      "             I-time      0.002     0.909     0.003        11\n",
      "     B-traffic_info      0.790     0.582     0.670       110\n",
      "     I-traffic_info      0.669     0.692     0.680       120\n",
      "B-weather_attribute      0.942     0.985     0.963       266\n",
      "I-weather_attribute      0.841     0.902     0.871        41\n",
      "\n",
      "        avg / total      0.603     0.831     0.659      3189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(\n",
    "    labels, preds, labels = sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('../dataset/kvret/kvret_test_public.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = random.choice(range(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get me directions to a local cafe\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-poi_type']\n",
      "navigate\n",
      "\n",
      "\n",
      "Yes.\n",
      "['O', 'O']\n",
      "navigate\n",
      "\n",
      "\n",
      "Thanks can you provide the address and is this the fastest route?\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-distance', 'O', 'O']\n",
      "navigate\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = random.choice(range(len(data)))\n",
    "history=[prepare_sequence([\"<null>\"],word2index).view(1,-1)]\n",
    "for d in data[index]['dialogue']:\n",
    "    \n",
    "    if d['turn']=='assistant':\n",
    "        phrase = nltk.word_tokenize(d['data']['utterance'])\n",
    "        phrase = prepare_sequence(phrase,word2index).view(1,-1)\n",
    "        history.append(phrase)\n",
    "    else:\n",
    "        h = pad_to_history(history,word2index)\n",
    "        c = nltk.word_tokenize(d['data']['utterance'])\n",
    "        c = prepare_sequence(c,word2index).view(1,-1)\n",
    "        with torch.no_grad():\n",
    "            slot_p, intent_p = model(h,c)\n",
    "        \n",
    "        slots = slot_p.max(1)[1]\n",
    "        intent = intent_p.max(1)[1]\n",
    "        slots = [index2slot[i] for i in slots.tolist()]\n",
    "        intent = index2intent[intent.item()]\n",
    "        print(d['data']['utterance'])\n",
    "        print(slots)\n",
    "        print(intent)\n",
    "        print(\"\\n\")\n",
    "        history.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = model.cpu()\n",
    "torch.save(model.state_dict(),'sden.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(word2index,open('vocab.pkl','wb'))\n",
    "pickle.dump(slot2index,open('slot.pkl','wb'))\n",
    "pickle.dump(intent2index,open('intent.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
